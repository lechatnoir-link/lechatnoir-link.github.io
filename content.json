{"pages":[{"title":"links","text":"なに，(⊙o⊙)？ ame","link":"/links/index.html"},{"title":"about","text":"Hello! I’m abel. I’m a Master’s student in Computer Science and Technology now. My research focuses on Information Extraction, Knowledge Graph in Natural Language Processing. My research skill is still relatively low now.😅 Thank you for visiting. I have created personal blogs many times before, by myself or using frameworks made by others such as Wordpress, Typecho and Jekyll; However, due to my blind pursuit of dynamic effects, the blog was designed more and more fancy, but the content was more and more empty, and even once the blog was dressed up as a personal love memorial website, making the blog stupid； After a year, I re-build my blog with the encouragement of my friend, the following provisions are made: Only three types of articles will be shared: Summaries of literature in my own research area and related fields; Summaries of techniques accumulated in the course of research, projects and personal practice; Non-regular personal summaries based on todo-list. In the three types of articles: The summary of the literature is required to be understandable and rewarding for those who have relevant research experience. Aka. quality assurance, preferring lack to lack; Technical summaries that I can read and understand, or I can quickly remember when I needs them, but that do not require that others understand the exact meaning; Personal summary requirements to todo-list-based. The blog can be revamped after a certain level of academic or technical achievement in order to “get the details right”; No more fancy plugins, features and pages on top of the current one; I strive to make this blog an accumulative testimony of personal thoughts and techniques, and if I’m busy or have nothing good to offer, I can break off, and perfunctory work is strictly prohibited. Contact me: Github Email","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"DeepLearning Environment Setting","text":"How to elegantly build a deep learning environment and debug and run your own programs locally using the resources of a remote server. Prerequisites 搭载了显卡和conda环境的服务器，服务器可以联网(能conda、pip及wget)； 自己在服务器的账号引入了conda和cuda的环境变量 本地下载了PyCharm或VSCode； 拥有服务器管理员权限或者与管理员沟通过开放端口(只限启用jupyter才需要) 基本运行环境创建Conda环境创建 登录自己服务器账号后，需要创建所需的虚拟环境： 1234conda create -n env_name python=3.7# 自己指定python版本conda remove -n env_name --all# 如果以后需要删除环境，则可以使用该命令 激活虚拟环境： 1234567conda activate env_name# 或者source activate env_name# 关闭环境：conda deactivate# 或source deactivate 安装自己所需要的第三方库： 1234pip3 install package_name# 或者临时使用清华源pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple package_name# 或者使用conda安装，自行搜索 PyCharm配置 新建项目，为了方便，最好保持本地项目和服务器所需要配置的目录名一样； 在新建项目处，Location处是本地的项目路径。 选择Preciously的解释器，并点击Add Interpreter，选择SSH; 如果本地已经在某个服务器上已经创建过解释器，则直接在Existing处选择即可，否则，依旧点此处，再点击...处进入SSH Configurations页面；点击+，输入服务器地址、用户名和密码，之后再OK–&gt;Next: 如果是第一次添加，则可能出现下图的情况，直接点击Move，再点Next按照提示操作 如下图，选择Existing，点击...，之后会出现一个选择路径的选项框，按照自己账户所存在的根目录(如home或者data)，在自己账号下面，逐步点击.conda–&gt;envs–&gt;需要的虚拟环境–&gt;bin–&gt;python3即可，选择OK和Create，按照提示进入项目中。 之后，选择Tools–&gt;Deployment–&gt;Configuration...；一般来说，现在已经有了SFTP的选项，因为刚刚创建SSH解释器时，这里也同时附带被创建了； 类似于选择.conda的操作，选择好Local path和服务器Deployment path，即后续项目代码同步的路径； 如果有需要排除同步的路径，例如模型本身或者较大的数据集，则可以在Excluded Paths中选好本地及服务器不同步的路径； 完成这些配置后，此时是默认不自动同步的，因此可以进入Tools–&gt;Deployment–&gt;Options..，将Upload changed files automatically to the default server改成On explicit save action，即自己按Ctrl+S时进行同步，当然也可以改成Always; 之后，在PyCharm的右下角，将&lt;no default server&gt;改成上面配置好的SFTP； 大功告成。 VSCode配置 VSCode的配置相对比较简单，因此这里中简述基本步骤，不做相信说明，有需要可自行网上检索 下载微软官方插件Remote - SSH； 在远程资源管理器中的右上角的小齿轮中，输入： 12345Host &lt;远程主机名称&gt; HostName &lt;远程主机IP&gt; User &lt;用户名&gt; Port &lt;ssh端口，默认22&gt; IdentityFile &lt;本机SSH私钥路径&gt; Host ：连接的主机名称，可自定义； Hostname ：远程主机的 IP 地址； User ：用于登录远程主机的用户名； Port ：用于登录远程主机的端口，SSH 默认为 22 ； IdentityFile ：本地的私钥文件 id_rsa 路径； 一开始是没有私钥文件的，需要使用以下方式得到： 本地： 12cd ~/.ssh# 复制 id_rsa.pub的内容 服务器： 1234cd ~/.sshvim authorized_keys# 然后将刚刚复制的文件粘贴进去# 若不熟悉vim请自行检索 之后，本地的id_rsa即为私钥 小齿轮还可以再新增其他服务器的或者其他账户的信息； 需要注意的问题： 创建好后，左下角可以选择连接服务器，连接后需要下载相应的插件，如python和jupyter相关； 有时候vscode的网络不好，连接服务器下载会非常慢，插件也是如此； 如果难以下载，可以本地下载好，包括服务器本身或者需要按照的插件，然后进入服务器的.vscode-server中进行配置，具体自行查询 配置远程Jupyter虽然使用debug也非常方便，但是有时候还是希望可以利用Jupyter的cell执行特点来执行代码。 因此，先在虚拟环境中pip install jupyter； 假设服务器有比较严格的防火墙，那么请提前确定好端口(假设是4399)，让管理员开启： 12sudo firewall-cmd --zone=public --add-port=4399/tcp --permanentsudo firewall-cmd --reload 之后，初始化jupyter配置： 产生配置文件： 1jupyter notebook --generate-config 设置密码： 1jupyter notebook password 复制密钥： 123cd ~/.jupytervim jupyter_notebook_config.json# 将password的value复制下来 配置端口： 12vim jupyter_notebook_config.py# 拉到最后 1234c.NotebookApp.ip = '*'c.NotebookApp.password = &quot;刚刚复制的密钥&quot;c.NotebookApp.open_browser = Falsec.NotebookApp.port = 4399 启动jupyter： 123jupyter notebook# 然后测试一下，例如浏览器输入 http://浏览器ip:4399# 输入token密码 注意，在哪里启动jupyter，那么其根目录就在哪里； 长期挂载： 1nohup jupyter notebook &gt; note.log &amp; 则会一直挂在后台，保持运行 在PyCharm中使用jupyter： 在项目中新建一个jupyter文件，打开后右上角设置其configuration: 选中Configured Server，输入http://xxx.xxx.xxx.xxx:4399，然后回到文件运行代码，运行时会提示输入密码，输入即可; 大功告成！ 后续若有新增，将会于此补充","link":"/2023/05/01/DeepLearning-Environment-Setting/"},{"title":"Literature Curation Plan","text":"Reorganize and Record the top-level papers I have read in a Todo-List way. Survey Attention is All you Need. (Transformer) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. (Bert) Improving Language Understanding by Generative Pre-Training. (GPT) Language Models are Unsupervised Multitask Learners. (GPT2) Language Models are Few-Shot Learners. (GPT3) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. (Prompt) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. (CoT) Augmenting Reinforcement Learning with Human Feedback. (RLHF) Training language models to follow instructions with human feedback. (InstructGPT) Toolformer: Language Models Can Teach Themselves to Use Tools. (Toolformer) Tech Report GPT-4 Technical Report. Sparks of Artificial General Intelligence: Early experiments with GPT-4. REFew-shot FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation. (FewRel) FewRel 2.0: Towards More Challenging Few-Shot Relation Classification. (FewRel2.0) Few-Shot Relational Triple Extraction with Perspective Transfer Network. (PTN) Query-based Instance Discrimination Network for Relational Triple Extraction. (QIDN) Relation-Guided Few-Shot Relational Triple Extraction. (RelATE) Joint TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking. (TPLinker) A Novel Cascade Binary Tagging Framework for Relational Triple Extraction. (CasRel) A Frustratingly Easy Approach for Entity and Relation Extraction. (PURE) A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling. (GRTE) PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction. (PRGC) OneRel:Joint Entity and Relation Extraction with One Module in One Step. (OneRel) RFBFN: A Relation-First Blank Filling Network for Joint Relational Triple Extraction. (RFBFN) UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction. (UniRel) NERDiscontinuous Unified Named Entity Recognition as Word-Word Relation Classification. (W2NER) Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks. (MAPtr) Discontinuous Named Entity Recognition as Maximal Clique Discovery. (Mac) Content will be continuously added.","link":"/2023/05/02/Literature-Curation-Plan/"},{"title":"Paper Notes Collection One","text":"Paper Notes Collection for Survey and Large Language Model. 论文笔记合集：对部分论文做主要内容概括 CoTNotes for Paper: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models Background本文主要进行CoT评估的任务分别为： Arithmetic Reasoning：数学推理，即图1中所示的数学问题； Commonsense Reasoning：常识推理； Symbolic Reasoning：符号推理。例如要求将出现单词的首字母或者尾字母拼接在一起，虽然人类很容易解决该问题，但对模型而言非常具有挑战性。 Motivation思维链(CoT)在人类思考活动中很常见。当我们思考问题的时候，往往不是直接得到答案，而是将问题分解，然后逐步向正确答案靠近。 类似地，以CoT方式对模型进行提示，理论上也能得到比较好的结果，这是因为很多数据集在训练时，直接给出问题和答案，然后然后让模型去学习，但是为什么会得到这个答案，模型可能并不了解，而引入CoT后，这些中间步骤会极大丰富模型学会为什么得到此答案的理由。 如图1所示： 传统的训练方法中，对于一个问题，直接给出答案，模型难以学到得到这个答案的具体原因； 而在CoT提示方法中，给出的不仅是答案，而是增加了得到这个答案的中间步骤(也就是思考的过程)，通过这种方式，引导模型在解决类似问题时，也会先生成中间步骤，再得到最终答案，以提高准确性。 本文发现，单纯增大模型的规模，不足以在一些具有挑战性的任务上提升对应的性能，比如上面提到的三个问题。 因此，本文通过两个简单的思想，探索了大模型的在不扩大规模的前提下，如何提高模型在这些推理问题上的性能。这两个思想主要是：以前的大量语料和参数量已经给了模型产生中间步骤的能力；通过提示的方式可以进行few-shot学习，而无需微调。 具体来说，就是人工设置每种任务类型的CoT提示，作为few-shot的学习示例，这里的图2以数学推理为例： 可以看到，对于标准(传统)提示而言，随着模型规模的增加，性能的确有上升；但要想达到监督模型所得到性能表现还有些困难，并且训练大规模的语言模型，所耗费的资源是很多的。 而在这些模型上，仅仅通过增加CoT的提示，便有了达到甚至超过监督模型的性能。 同时也能看出，CoT提示在规模比较大的模型上表现的更好，也许说明了，模型的规模越大，越有利于产生中间结果，越利于进行few-shot学习，再配合上合适的提示，大模型的性能才能被更好地被发挥出来。 ToolformerNotes for Paper: Toolformer: Language Models Can Teach Themselves to Use Tools Motivation大语言模型(LLM)虽然在few-shot和zero-shot方面实现了非常好的提升，并通过参数规模、语料增加而展现了其“涌现”的特点，但这些模型依旧存在一些固有的限制，例如：从最近的事件中获取最新的信息；精确的数学计算；理解低资源语言；缺乏对时间进程的感知等。 但我们知道在日常生活中，早就有相关的工具能够很好的解决这些问题，那就是各种实用工具，比如搜索引擎、计算器和日历等。如果让大语言模型能够学会如何正确地使用这些工具，而不是寄希望于让他们自己解决所有问题，将极大节省训练的花费。为此，本文提出了Tooformer，以让模型拥有使用外部工具的能力，他们的方法主要有以下几个特点： 要能以自监督的方式学习，因为大量的人工标注是昂贵的；此外，人类认为有用的信息，对模型而言则不一定，因此让模型自己学习或许更有益； 语言模型不应该失去它的通用性，应该能够自己决定何时、如何使用哪种工具。与现有的方法相比，这使得对工具的使用更加全面，不受特定任务的束缚。 文中的调用方式为： 分别表示只有调用本身和一个调用包含其结果。下图的示例就是一个调用(c)的工具(a)，输入(i)和结果(r)。 作者们构建这种使用外部工具的模型的主要方法大致为： 首先让语言模型自己对大量的数据集按照自己的方式进行可能的API调用标注(因为现有的人工写的好的API调用例子并不多)； 然后，再利用自监督损失来确定哪些API调用切实有助于模型的预测； 最后，利用这些有用的API注释来微调模型。 如图所示： 首先对于输入文本，先让语言模型利用其上下文学习能力去生成大量可能的API调用示例，再实际去执行这些API调用，然后用空序列调用做对比进行自监督损失以选出更可能有效的API调用，最后再利用这些API进行微调。 本文主要使用了以下几种工具，利用GPT-J(6B)做微调的模型，实验结果的确有效，很多数据集上甚至比OPT(66B)和GPT3(175B)高得多：1). 问答；2). 计算器；3). 维基百科搜索；4). 机器翻译；5). 日历。 RLHFInstructGPT","link":"/2023/05/10/Paper-Notes-Collection-One/"},{"title":"Server Management Notes","text":"A summary of some common commands that are used to manage servers. 管理员账户相关rootUbuntu默认是没有root的，而是以sudo用户来代替，这种方式在绝大多数时候是安全可用的，但当sudo用户有操作不当时，会导致系统出现无法修复的问题，因此在有这种需要时，可以提前设置root用户。 在具有sudo权限的用户下进行操作； 设置root账户密码： 1passwd root 编辑配置文件： 1234sudo vim /etc/ssh/sshd_config# 然后输入以下命令：PermitRootLogin yesPasswordAuthentication yes 重启ssh服务： 1systemctl restart ssh 需要注意，root用户具有完全的权限，比一般的sudo用户更高，使用时务必小心。 sudo在某个管理员账户下，给某个用户分配sudo权限，一种简单的方式是将其添加到sudo的组里面； 查看sudo用户： 12345678# 查看sudo用户有哪些# 先安装一个包sudo apt-get install members# 再查看members sudo# 或者在某个用户的终端下输入groupsgroups # 以查看该用户当前所属的组 将用户添加到sudo组： 12sudo usermod -aG sudo username# 将username替换为用户账户名 将用户从sudo组移除： 1sudo deluser username sudo 网络配置相关参考: asimok’s blog 端口防火墙： 打开某个端口的防火墙 12sudo firewall-cmd --zone=public --add-port=4399/tcp --permanentsudo firewall-cmd --reload 配置ipv6： 检查是否已经启用ipv6支持 1sudo cat /proc/net/if_inet6 如果结果不为空，直接下一步，否则： 12345678sudo vim /etc/sysctl.conf# 添加以下内容:net.ipv6.conf.all.disable_ipv6 = 0 net.ipv6.conf.default.disable_ipv6 = 0# 之后，执行：sudo sysctl -p# 检查是否启用：sudo cat /proc/net/if_inet6 先找一个比较快的ipv6的DNS，比如清华源等； 修改配置文件，添加DNS: 123sudo vim /etc/systemd/resolved.conf# 添加DNS，比如：DNS=2001:67c:2b0::6 2001:67c:2b0::4 重启DNS服务： 12sudo systemctl restart systemd-resolved sudo systemctl enable systemd-resolved 启动配置文件： 123sudo mv /etc/resolv.conf /etc/resolv.conf.bak# 先将原来的文件备份sudo ln -s /run/systemd/resolve/resolv.conf /etc/ 检查是否启用成功： 1sudo cat /etc/resolv.conf","link":"/2023/05/11/Server-Management-Notes/"},{"title":"Todo-List 2023 Spring","text":"Basic schedule from May to September 2023 May4th Week 整理和打印分布式系统各项资料 复习分布式系统，完成应试准备 基本完成论文代码的修改和运行测验 基本完成大模型的数据工作、项目的模型收尾工作 3rd Week这一周真的光玩塞尔达了！！但是太好玩啦！ 塞尔达-王国之泪！！！！！！！！ 2nd Week 完成W2NER的论文笔记 完成CoT的论文笔记(in 论文合集1) 完成实习项目算法部分的余下全部内容，并完善和修改以前部署的部分 项目交接 1st Week 完成分布式系统的课件整理和概览 完成非科研和课业内容的前期杂事 完成第二版代码的修改和验证性训练","link":"/2023/05/02/Todo-List-2023-Spring/"},{"title":"W2NER","text":"Notes for Paper: Unified Named Entity Recognition as Word-Word Relation Classification 论文笔记主要记录和分析论文动机和思想，不对具体方法的细节和实验做讨论 Background:现有的NER问题可以大致分成三种： 简单实体(flat)，实体的构成比较简单，只识别出实体的开始和结束位置即可； 重叠(嵌套)实体(overlapped)，会出现多个实体包含相同的token的情况； 不连续实体(discontinuous)，实体由位置上不相邻的token构成。 如图1所示，在(a)中的实体$e_1$就是简单实体，而$e_2$则是不连续实体。又因为这两个实体同时出现在同一个句子中，并且有相互重叠的部分，即aching in，因此它们又是重叠的实体。 现有的NER方法大致可分为四种： 序列标注方法，简单来讲就是对每个token分配一个标签，以识别每个token在一个实体中扮演的角色。如图1中的$e_1$，我们可以将aching in legs分别标为BIE，以表示他们为开始、中间和结束。虽然这种方式简单直观，但是缺陷也很明显，即出现重叠和非连续实体时，简单的标签就无法完成任务了，并且还需要仔细地设计多种标签，复杂度非常高，也不利于解码； 基于超图的方法，既然标注法对一个token只能分配一个标签，那么利用节点和边的特点(一个节点可以有多个边)来表示所有的实体span，在一定程度上缓解了标注法的实体嵌套问题，但推理时会受到虚假结构和结构模糊性问题的影响(原文如此说，因为还没读过相关方法的论文，没有理解，暂时划掉)； 序列生成的方法：既然标注很麻烦，那干脆利用Seq2Seq的方式，直接生成实体，这样会不受嵌套和不连续的影响，但是会受到解码效率和偏差暴露的影响； 基于span的方法：一般可以列举所有可能的span，然后对span进行分类，但这种方式不仅会受到span的长度限制，还会因为枚举造成大量的资源消耗。 Motivation：本文认为，上述方法的核心其实还是在寻找实体的边界，这种思想也许在解决某一个具体问题上有效，但如果想同时解决三种实体识别的问题，也就是建立一个统一的NER模型，那就不能仅仅只看实体的边界了。 因此，本文认为这种统一模型的主要瓶颈在于如何建模好单词之间的相邻关系，因为只确定边界只是确定了实体的大致范围，至于词之间的关系：是复用的还是不相邻的？需要用其他方式来表示。 所以本文提出了自己的方法W2NER，该方法主要对词之间的两类关系，准确地说是三类关系进行建模，即： None:无关系； NNW(Next-Neighboring-Word)：下一个邻接词； THW-*:(Tail-Head-Word-*): 头尾词，*表示实体类型 简单来说，THW确定了所有可能的实体边界，NNW确定了实体边界里面的各词之间的关系。如图2所示: THW-S确定了两个S(Symptom)类型的实体范围，(从尾找到头)：aching in legs 和 aching in legs and shoulders； NNW确定了词之间的关系，即当前单词的下一个词是谁，可以看到in和and并没有NNW关系，所以在两个实体范围中，只能解码出:aching in legs和aching in shoulders两个实体，而这样恰好解决了不连续的问题。 这种思想也可以结合图2和图1(b)来直观地感受。 Model and Experiment:本文使用了Bert和LSTM作为编码器，利用卷积层提取词之间的表示，最后利用双仿射和多层感知机联合分类出词之间的关系。模型总体结构如图3所示： 使用卷积层的目的非常直观，因为本文建模的方式就是表的形式，而CNN相对也很适合处理这种结构的表示。在卷积层中，使用了条件层归一化操作(Conditional Layer Normalization)，论文认为这样能够有效产生词对的网格(表)的表示；之后利用类似Bert的方式，增加了词的位置信息和表格的区域信息；最后，使用不同的空洞卷积以捕获不同词距离之间的交互信息。 在完成上面对表格的表示refine后，论文使用联合的预测器进行最后的token标记分类。因为原文提到先前的工作验证了MLP和biaffine联合使用有利于关系分类。 具体的实验内容可见原文，这里以ShARe14数据集为例，如下图，可见W2NER模型在重叠和不连续场景长的确都取得了明显的性能提升。 Decode Strategy:解码的基本思想是利用词之间的关系来确定词和词之间的路径，文中以四个示例来展示解码的具体操作： 需要注意的是，图中的下方文字，划线的是具体的实体，大写字母代表了实体中的词。而图中的蓝线表示NNW关系，红色的线表示THW关系。 有两个实体AB和DE，属于简单实体，因此直接就能解码出来； 有重叠的实体：ABC和BC，但因为ABC和BC均有THW关系，因此也可以解码除了； 有重叠和不连续的实体：ABC和ABD，除了利用THW关系来解决重叠问题外，NNW也从B直接关联到D，从而识别出了不连续的ABD实体； 比较复杂的实体：ACD和BCE，和上面不同的在于，有可能出现ACE和BCD的路径，但是通过THW的限制，使得这两种情况被排除。 Thinking: 本文的动机、对应解决方法和解码策略都非常自然，需要注意的是： 并非所有表格表示的东西都适合CNN，如果token的分类和其他token没有太多直接的关系，那么使用CNN不一定会有正向的作用；当然，本文中因为NNW关系本就需要邻近token的信息，所以非常适合，但是核不易太大； 这种方法可以迁移到关系提取(联合提取)上，但是重叠的类型会更多，并且会引入超出实体级别的关系。如果依旧保留NNW这样的关系，可能造成模型学习的负担，并且很容易和其他标签重叠，因此必然需要进一步的修改标签和编码方式。","link":"/2023/05/02/W2NER/"},{"title":"hello world","text":"Some things about the blog Demo此处以Hexo创建GitHub Pages静态页面为例，作为后续技术总结的参考。 创建Github Repo: 默认已经注册有自己的Github账户了； 新建repository: 在仓库名字处，写上username.github.io； 这个username就是自己github注册的名字。例如自己进入自己github的主页时显示为xxx，则新建仓库时名字就为”xxx.github.io”； 配置Git SSH: 在自己电脑本地下载Git，比如Git for Windows； 在Git Bash里面输入： 12git config --global user.name \"your user name\"git config --global user.email \"your github email\" 之后: 123ssh-keygen -t rsa -C \"your github email\"# 之后按照提示操作即可，或者直接三个回车到底cd ~/.ssh 将.pub文件的内容复制好，进入github的settings页面，点击SSH and GPG keys，新增SSH keys，在key中复制刚刚剪切板的内容； 安装npm和Hexo: 在本地安装npm，如Node.js (nodejs.org) 进入Hexo官网，按照提示在本地希望后续保存博客的路径中，用Git Bash逐个输入： 12345npm install hexo-cli -ghexo init your_blog_namecd your_blog_namenpm installhexo server 之后，就可以在浏览器中输入：localhost:4000查看本地博客是否成功创建 配置Hexo: 在该博客路径中，打开_config.yml中修改各种信息，可以参考：配置 | Hexo 希望创建新的页面，比如about或者links等，输入: 1hexo new page \"about\" 之后在source/about/index.md中进行修改即可 希望创建新的文章，输入： 1hexo new \"hello world\" 之后在source/_post中修改对应名字的文章即可 部署Hexo: 要将博客部署在刚刚创建的xxx.github.io中，则打开本地博客的_config.yml，找到deploy处，修改为： 1234deploy: type: git repo: https://github.com/xxx/xxx.github.io branch: main 之后安装依赖，输入： 1npm install hexo-deployer-git --save 完成后，分别输入以下命令： 123hexo cleanhexo g # 产生静态文件hexo d # 自动部署到github.io页面 等待大概3分钟，即可在https://xxx.github.io里面看到自己的博客内容了。 启动latex渲染： 注意，保持原版不变即可，不需要再在网上查找各种复杂的教程安装各种包； 输入以下命令安装包： 1npm install hexo-filter-mathjax 进入博客的_config.yml，在末尾添加以下内容： 1234567891011mathjax: tags: none # or 'ams' or 'all' single_dollars: true # enable single dollar signs as in-line math delimiters cjk_width: 0.9 # relative CJK char width normal_width: 0.6 # relative normal (monospace) width append_css: true # add CSS to pages rendered by MathJax every_page: false # if true, every page will be rendered by MathJax regardless the `mathjax` setting in Front-matter packages: # extra packages to load extension_options: {} # you can put your extension options here # see http://docs.mathjax.org/en/latest/options/input/tex.html#tex-extension-options for more detail 之后，对于需要使用latex的文章，在其front-matter处增加mathjax: true，再重新生成和部署博客即可。 123456---title: Enable Latex on your articlecategories: Exampledate: 1905-06-30 12:00:00mathjax: true--- 公式示例： 行间公式： This is a in-line latex demo: 块间公式： 安装自定义字体： 如果需要引用google在线字体，可自定于网络搜索； 考虑到很多时候引用网络字体会出现不可预见的情况，因此可以将自己心仪字体的ttf下载下来； 假设下载的字体文件为abc.ttf； 在博客当前所使用的主题路径下:source/css，找到可能的字体文件样式表，如果没有，则自行创建。此次假设该文件叫：style.styl； 将字体文件放在样式路径下面，比如创建source/font目录，并将abc.ttf放在该font目录下； 在style.styl中，新增或修改： 12345678@font-face{ font-family: 'abc'; src: url('../font/abc.ttf')}body { font-family: 'abc';} 此处也可以推广，即url可以新增更多字体，也包括网络字体； body中指定的为网页字体渲染的顺序。 然而，在部署到远程服务器上时，有可能存在相对路径错误导致无法看到字体的情况，那么应该结合实际产生的静态文件的路径配置，自行修改src: url('../font/abc.ttf')的地址。 Hexo文章中插入图片： 使用markdown时，插入图片非常方便，但在早期的Hexo中，相关的操作并不友好； 在Hexo 3时代，我们可以通过非常简单的方法完成以前相对繁琐的操作； 首先，确保博客node_modules中有hexo-renderer-marked包，没有则安装： 1npm install hexo-renderer-marked --save 之后，在博客的_config.yml中修改和新增： 1234post_asset_folder: truemarked: prependRoot: true postAsset: true 之后使用命令新增文章时，会同时创建同名的资源文件夹，可以在里面放置图片等资源，然后在文章中使用markdown语法插入图片即可，并且只需要指定资源的名字，不用再指定路径，因为它默认在同名的资源文件中查找相关资源。 1![插入图片](image.jpg) Hexo总结： 如果需要更改默认主题，则在相关的主题网站查找Hexo主题，按照他们的说明进行下载和修改。一般来说主要经过下载–改名–放入博客theme路径–修改博客_config中的theme选项–修改主题文件的配置 这些流程； 如果需要新建分类： 1hexo new page categories 之后进入surce/categories/index.md并修改为： 12345---title: categoriesdate: 2023-05-01 13:47:40type: \"categories\"--- 后续新建文章后，只需要在文章标头中增加categories: 自定义类别名即可 如果需要新建标签： 同上，无非是将相关的categories改为tags即可。 如果需要对文章显示其摘要：由于大多数主题不支持自定义摘要，因此可以在希望显示的文字后面加上： 1&lt;!-- more --&gt; 本地服务器预览 1hexo s 新建文章 123456hexo n \"新文章\"# 新建文章hexo n page new_page# 新建页面hexo new page --path about/me \"About me\"# 指定路径新建页面 此外，文章还可以有很多属性，包括但不限于： layout ：page或者post title：文章标题 date：创建日期 updated：修改日期 comments ：是否开启评论，默认true tags：标签名 categories：分类名 产生静态文件（假设要部署在自己的服务器上，则需要手动移动静态文件) 1hexo g 清除缓存 1hexo clean 存储草稿 1hexo new draft \"new draft\" 该命令会生成source/_draft/new-draft.md，这些文章不会被发表，不会被链接查看到，可以当作自己撤销的、临时的或者私密的文章来用。 部署博客 123hexo dhexo clean &amp;&amp; hexo d# 一般可以用组合命令 后续若有新增，将会于此补充","link":"/2023/05/01/hello-world/"}],"tags":[{"name":"tech-notes","slug":"tech-notes","link":"/tags/tech-notes/"},{"name":"todo-list","slug":"todo-list","link":"/tags/todo-list/"},{"name":"paper-notes-collection","slug":"paper-notes-collection","link":"/tags/paper-notes-collection/"},{"name":"paper-notes","slug":"paper-notes","link":"/tags/paper-notes/"},{"name":"official","slug":"official","link":"/tags/official/"}],"categories":[]}